# gradient-descent-from-scratch
First I have laid foundational mathematics behind this concept, then I coded it and used it in a demo dataset.
<br><br>
My implementation and math, achieves 98% accuracy.
<br><br>
I have also used libraries such as njit to make training faster.
<br><br>
Njit turns your python code into compiled code and this is why your code can run at a great speed especially if you are using high number of loops, execution of similar or same code. If you don't know, python is not compiled but interpreted this is why it runs slower than compiled languages.
<br><br>
This was my homework at 2024, but when I looked back on it I realized it is a great work and I wanted to upload it to github.
<br>
![math-image](https://media.licdn.com/dms/image/v2/D4D2DAQGZifzEQI57nQ/profile-treasury-image-shrink_800_800/B4DZZcPtVwG0Ac-/0/1745304344462?e=1746100800&v=beta&t=00K0zlztVD4K8JEuZ2gXEp56xOyR7QAswU7WHgwEzJE)
![train-test-loss](https://media.licdn.com/dms/image/v2/D4D2DAQG1jkTuGUUEFQ/profile-treasury-image-shrink_800_800/B4DZZcSF2QGsAY-/0/1745304969005?e=1746100800&v=beta&t=K-Lb9nS54P9cTGfCgf1TxHp4xccLBifW-BIxifJjbC4)
